{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTING STARTED\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data file\n",
    "df = pd.read_csv('survey_results_public.csv')\n",
    "# Load the file that describes what the columns mean\n",
    "df_schema = pd.read_csv('survey_results_schema.csv')\n",
    "\n",
    "# Display data frame (first 20 columns)\n",
    "df \n",
    "# Display first(head) or last (tail) 10 rows\n",
    "df.head(10)\n",
    "df.tail(10)\n",
    "\n",
    "# An attribute that returns number of columns and rows (85 columns and 80,000+ rows)\n",
    "df.shape\n",
    "# Returns the datatypes of the columns. An object is usually a string\n",
    "df.info()\n",
    "\n",
    "# Change options to display all columns and all rows in the schema\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASICS\n",
    "\n",
    "# Access a specific column, returns a series\n",
    "df['Hobbyist']\n",
    "# A 1 dimensional array / 'a single column of rows'\n",
    "df(df['Hobbyist'])\n",
    "# Does the same thing but can cause side effects\n",
    "df.email\n",
    "\n",
    "# Access multiple columns by giving it a list, no longer a series\n",
    "df[['Employment', 'Hobbyist']]\n",
    "# Access all columns\n",
    "df.columns\n",
    "\n",
    "# Access rows by integer location (iloc)\n",
    "df.iloc[0] # First row\n",
    "df.iloc[[0, 1]] # First and second row\n",
    "df.iloc[[0, 1], 2] # Fist 2 rows of column 2\n",
    "\n",
    "# Access rows by lable location\n",
    "df.loc[0] # First row\n",
    "df.loc[0, 1, 2] # First 3 rowa\n",
    "df.loc[0, 'Hobbyist'] # Single row for the Hobbyist column\n",
    "df.loc[[0, 1], 'Hobbyist'] # Fist 2 rows of column Hobbyist\n",
    "df.loc[[0, 1], ['Hobbyist', 'last']] # Fist 2 rows of column Hobbyist and last\n",
    "df.loc[0:2, 'Hobbyist':'Employment'] # Slice first 3 rows of the slice Hobbyist to Employment columns\n",
    "\n",
    "# Returns how many values of each row there is (71257 yes, 17626 no)\n",
    "df['Hobbyist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEXES\n",
    "\n",
    "# Modify the index, doesnt change the actual df\n",
    "df.set_index('Hobbyist')\n",
    "# Perminatly modifies the df\n",
    "df.set_index('Hobbyist', inplace=True)\n",
    "# now we can search by element\n",
    "df.loc['millie.jackson1@gmail.com']\n",
    "df.loc[0] # This no longer works\n",
    "# Reset to default index\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Set the index when you open the file\n",
    "df = pd.read_csv('survey_results_public.csv', index_col='Respondent')\n",
    "df.loc[1] # First respondent\n",
    "df_schema = pd.read_csv('survey_results_schema.csv', index_col='Column')\n",
    "df_schema.loc['Hobbyist'] # Look up the Hobbyist column descriptions\n",
    "df_schema.loc['MgrIdiot', 'QuestionText'] # Look up column and row\n",
    "\n",
    "# Sort alphabetically\n",
    "df_schema.sort_index()\n",
    "df_schema.sort_index(ascending=False) # Backwards\n",
    "df_schema.sort_index(ascending=False, inplace=True) # Makes it perminant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERING\n",
    "\n",
    "# Returns the number of entries in the last column\n",
    "filt = df['Hobbyist'] == 'Yes'\n",
    "# Show them all\n",
    "df[filt]\n",
    "df.loc[filt]\n",
    "# This works too\n",
    "df[df['Hobbyist'] == 'Yes']\n",
    "\n",
    "# Locate a single item\n",
    "# & = +\n",
    "filt = df['Hobbyist'] == 'Yes' & df['first'] == 'John'\n",
    "df.loc[filt]\n",
    "# Locate this item or this item \n",
    "# | = or\n",
    "filt = df['Hobbyist'] == 'Yes' | df['first'] == 'John'\n",
    "df.loc[filt]\n",
    "# Locate everything that isnt\n",
    "df.loc[~filt]\n",
    "\n",
    "# Make a filter to find all the salaries abover 70000\n",
    "high_salary = df['ConvertedComp'] > 70000\n",
    "df.loc[high_salary]\n",
    "\n",
    "# Apply filter to these columns\n",
    "df.loc[high_salary, ['Country', 'LanguageWorkedWith', 'ConvertedComp']]\n",
    "\n",
    "# Use a variable to hold a list of items\n",
    "countries = ['United States', 'India', 'United Kingdom', 'Germany', 'Canada']\n",
    "filt = df['Country'].isin(countries)\n",
    "df.loc[filt, 'Country']\n",
    "\n",
    "# Search the languages for a specific language, 'does the string contain 'Python'\n",
    "filt = df['LanguagesWorkedWith'].str.contains('Python', na=False) # control for na edge cases\n",
    "df.loc[filt, 'LanguagesWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATING ROWS AND COLUMNS\n",
    "\n",
    "# Change all column names\n",
    "df.columns = ['first_name', 'last_name', 'email']\n",
    "# Change all column names to uppercase\n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "# Change all spaces to underscores\n",
    "df.columns = df.columns.str.replace('', '_')\n",
    "# Use a dictoinary of names you want to change\n",
    "df.rename(columns={'first_name': 'first', 'last_name': 'last'}, inplace=True)\n",
    "# Rename items\n",
    "df.loc[2] = ['John', 'Smith', 'JohnSmith@email.com']\n",
    "df.loc[2, ['last, 'email']] = ['Doe', 'JohnDoe@email.com']\n",
    "df.loc[2, 'last'] = 'Smith'\n",
    "df.at[2, 'last'] = 'Doe'\"Data Cleaning Practical.ipynb\"\n",
    "\n",
    "# Apply a filter and change the name\n",
    "filt = (df['email'] == 'JohnDoe@email.com')\n",
    "df.loc[filt, 'last'] = 'Smith'\n",
    "\n",
    "# Apply changes to multiple items\n",
    "df.['email'] = df['email'].str.lower()\n",
    "\n",
    "# See how many rows in the column\n",
    "df.apply(len)\n",
    "# See how many rows in a specific column\n",
    "len(df['email'])\n",
    "# See how many columns in a specific row\n",
    "df.apply(len, axis='columns')\n",
    "\n",
    "# See the character count for each email\n",
    "df['email'].apply(len)\n",
    "\n",
    "# Build a function to pass in as a perameter\n",
    "def update_email(email):\n",
    "    return email.upper()\n",
    "\n",
    "df['email'] = df['email'].apply(update_email)\n",
    "\n",
    "# Using lambda functions\n",
    "df['email'] = df ['email'].apply(lambda x: x.lower())\n",
    "\n",
    "df.apply(pd.Series.min)\n",
    "df.apply(lambda x: x.min())\n",
    "\n",
    "# Only works on df not series\n",
    "df.applymap(len)\n",
    "df.applymap(str.lower)\n",
    "\n",
    "# Only works on Series not df\n",
    "# Used to substitute one value for another\n",
    "# Values not changed will become 'NaN' not a number\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})\n",
    "# This changes the one we want and keeps the origionals unchanged\n",
    "df['first'].replace({'Corey': 'Chris', 'Jane': 'Mary'})\n",
    "\n",
    "# Examples\n",
    "df.rename(columns={'ConvertedComp': 'SalaryUSD'}, inplace=True)\n",
    "df['Hobbyist'] = df['Hobbyist'].map({'Yes': True, 'No': 'False'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD AND REMOVE ROWS AND COLUMNS\n",
    "\n",
    "# Combine first name and last name columns\n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "# Pass a list of which columns to remove\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "# Split fullname into two columns\n",
    "df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# Add a single row\n",
    "df.append({'first': 'Tony'}, ignore_index=True)\n",
    "\n",
    "# Make a new df\n",
    "people = {\n",
    "    'first': ['Tony', 'Steve'],\n",
    "    'last': ['Stark', 'Rogers'],\n",
    "    'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "    }\n",
    "\n",
    "df2 = pd.DataFrame(people)\n",
    "# Add 2 df together\n",
    "# An error hear means that you passed the information in the wrong order 'sort' ignores this\n",
    "df.append(df2, ignore_index=True, sort=False)\n",
    "# Remove a row\n",
    "df.drop(index=4)\n",
    "# Remove all instances of last name Doe\n",
    "df.drop(index=df[df['last'] == 'Doe'].index)\n",
    "# Or\n",
    "filt = df['last'] == 'Doe'\n",
    "df.drop(index=df[filt].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORTING DATA\n",
    "\n",
    "# Sort 2 columns alphabeticly backwards\n",
    "df.sort_values(by=['last', 'first'], ascending=False)\n",
    "# Forwards first then backwards\n",
    "df.sort_values(by=['last', 'first'], ascending=[False, True], inplace=True)\n",
    "# Return to the origional\n",
    "df.sort_index()\n",
    "# Show sorted last names only\n",
    "df['last'].sort_values\n",
    "\n",
    "# Examples\n",
    "df.sort_values(by=['Country', 'ConvertedComp'], ascending=[True, False], inplace=True)\n",
    "df[['Country', 'ConvertedComp']].head(50)\n",
    "df['ConvertedComp'].nlargest(10) # Get the 10 largest salarys\n",
    "df.nlargest(10, 'ConvertedComp') # Gets the details for those 10 largest salarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPING AND AGGREGATING\n",
    "\n",
    "# Get the mean salary\n",
    "df['ConvertedComp'].median()\n",
    "# Get the mean on all numerical columns\n",
    "df.median()\n",
    "# Get different stats 'quick overview'\n",
    "# Count = number of missing rows\n",
    "df.describe()\n",
    "df['ConvertedComp'].count()\n",
    "# how many said 'yes' or 'no'\n",
    "df['Hobbyist'].value_counts()\n",
    "\n",
    "df['SocialMedia'].value_counts() # Get the counts for each answer\n",
    "df['SocialMedia'].value_counts(normalize=True) # Percentatges\n",
    "\n",
    "df['Country'].value_count() # How many from each country\n",
    "country_grp = df.groupby(['Country']) # Returns an object\n",
    "country_grp.get_group('United States') # Shows all results for a specific country\n",
    "# Same as doing this\n",
    "filt = df['Country'] == 'United States'\n",
    "df.loc[filt]\n",
    "# To see most popular social media by that country\n",
    "df.loc[filt]['SocialMedia'].value_counts()\n",
    "# To see most popular social media for all countries\n",
    "country_grp['SocialMedia'].value.counts()\n",
    "country_grp['SocialMedia'].value.counts().loc['India'] # Just for india\n",
    "\n",
    "country_grp['ConvertedComp'].median() # Show maen salary\n",
    "country_grp['ConvertedComp'].median().loc['Germany'] # Show maen salary in Germany\n",
    "country_grp['ConvertedComp'].agg(['median', 'mean']) # Returns the mean and median for each country\n",
    "country_grp['ConvertedComp'].agg(['median', 'mean']).loc['Canada'] # Returns the mean and median for canada\n",
    "\n",
    "filt = df['Country'] == 'India' # Show info for India\n",
    "df.loc[filt]['LanguageWorkedWith'].str.contains('Python') # Find all cases of Python use in India\n",
    "df.loc[filt]['LanguageWorkedWith'].str.contains('Python').sum() # Shows how many\n",
    "country_grp['LanguageWorkedWith'].apply(lambda x: x. str.contains('Python').sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT % OF PEOPLE FROM EACH COUNTY KNOW PYTHON?\n",
    "\n",
    "# How many people from each country\n",
    "country_respondents = df['Country'].value_counts()\n",
    "# How many from each country use python\n",
    "country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x. str.contains('Python').sum())\n",
    "# Merge both together\n",
    "python_df = pd.concat([country_respondents, country_uses_python], axis='columns', sort=False)\n",
    "# Rename to more suitable column names\n",
    "python_df.rename(columns={'Country': 'NumRespondents', 'LanguageWorkedWith': 'NumKnowsPython'}, inplace=True)\n",
    "# Make a df of percentage of people who know python by country\n",
    "python_df['PctKnowsPython'] = (python_df['NumKnowsPython']/python_df['NumRespondents']) * 100\n",
    "# Sort from highest to lowest percentage\n",
    "python_df.sort_values(by='PctKnowsPython', ascending=False, inplace=True)\n",
    "# Show first 50\n",
    "python_df.head(50)\n",
    "# Show just Japan\n",
    "python_df.loc['Japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING DATA\n",
    "\n",
    "# Remove rows that dont have any data at all\n",
    "df.dropnp()\n",
    "df.dropnp(axis='index', how='any') # Default arguments index = rows any = any na\n",
    "df.dropnp(axis='index', how='all') # Only removes ros when all values are na\n",
    "\n",
    "# Checks email column for valid values in email and last name\n",
    "# We need either an email or a last name\n",
    "df.dropnp(axis='index', how='any', subset=['email', 'last'])\n",
    "\n",
    "# Replace all missing values with np.nan\n",
    "df.replace('NA', np.nan, inplace=True)\n",
    "df.replace('missing', np.nan, inplace=True)\n",
    "# Returns a mask of what it is including as na values\n",
    "df.isna()\n",
    "\n",
    "# Replace all na with a value\n",
    "df.fillnp('MISSING')\n",
    "df.fillnp('0')\n",
    "\n",
    "# Shows data type of columns\n",
    "df.dtypes\n",
    "type(np.nan) # Retures a float\n",
    "# Convert all values in the age column to a float\n",
    "df['age'] = df['age'].astype(float)\n",
    "# Get mean for that column\n",
    "df['age'].mean()\n",
    "\n",
    "# Variable for all na values\n",
    "na_vals = ['NA', 'Missing']\n",
    "# Use it at the begining when opening the file to replace all with NaN\n",
    "df = pd.read_csv('survey_results_public.csv', index_col= 'Respondent', na_values=na_vals)\n",
    "\n",
    "# Show first 10\n",
    "df['YearsCode']\n",
    "# Convert to float\n",
    "df['YearsCode'] = df['YearsCode'].astype(float) # Wont work\n",
    "# Find all values that are unique\n",
    "df['YearsCode'].unique()\n",
    "# Replace all 'less that one years with '0'\n",
    "df['YearsCode'].replace('Less that 1 year', 0, inplace=True)\n",
    "df['YearsCode'].replace('More that 50 year', 51, inplace=True)\n",
    "df['YearsCode'] = df['YearsCode'].astype(float) # Now it works\n",
    "df['YearsCode'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATES AND TIMES\n",
    "\n",
    "# Run a datetime function to see if it is the right format\n",
    "df.loc[0, 'Date'].day_name()\n",
    "# Convert to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %I-%p')\n",
    "# You can do this when you read in the file\n",
    "d_parser = lambda x: pd.datetime.strpttime(x, '%Y-%m-%d %I-%p') # Convert a str to datetime\n",
    "df = pd.read_csv('survey_results_public.csv', parse_dates=['Date'], date_parser=d_parser)\n",
    "# Get the dayname for all values\n",
    "df['Date'].dt.day_name()\n",
    "# Make it a new column\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "# Get the earlyest date\n",
    "df['Date'].min()\n",
    "# Get the time delta (time between two events)\n",
    "df['Date'].max() - df['Date'].min()\n",
    "\n",
    "# Make a filter to narrow down the data\n",
    "filt = (df['Date'] >= '2020')\n",
    "filt = (df['Date'] >= pd.datetime('2019-01-01')) & (df['Date'] < pd.datetime('2020-01-01'))\n",
    "df.loc(filt)\n",
    "# Make a slice\n",
    "df.set_index('Date', inplace=True) # Make date the row name\n",
    "df['2019']\n",
    "df['2020-01':'2020-02']['Close'].mean()\n",
    "\n",
    "# View by day\n",
    "df['2020-01':'2020-02'].head(24)\n",
    "df['2020-01']['High'].max()\n",
    "# Resample to 3 days\n",
    "highs = df['High'].resample('3D').max()\n",
    "highs['2020-01-01']\n",
    "# Make a graph\n",
    "%matplot inline\n",
    "highs.plot()\n",
    "# Resample whole df by week, using a dictionary of instructions\n",
    "df.resample('W').agg({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE FORMATS\n",
    "\n",
    "# CSV\n",
    "from xmlrpc.server import XMLRPCDocGenerator\n",
    "df = pd.read_csv('data/file.csv')\n",
    "df.head()\n",
    "df.to_csv('data/modified.csv')\n",
    "\n",
    "# TSV\n",
    "df = pd.read_csv('data/file.tsv', sep='\\t')\n",
    "\n",
    "# EXEL\n",
    "pip install xlwt openpyxl xlrd\n",
    "df.to_excel('data/modified.xlsx')\n",
    "test = pd.read_excel('data/modified.xlsx', index_col='Respondent')\n",
    "\n",
    "# JSON\n",
    "df.to_json('data/modified.json', orient='records', lines=True)\n",
    "test = pd.read_json('data/modified.json', orient='records', lines=True)\n",
    "\n",
    "# SQL\n",
    "pip install SQLAlchemy psycopg2-binary\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "engine = create_engine('postgresql://dbuser:dbpass@localhost:5432/sample_db')\n",
    "df.to_sql('sample_table', engine, if_exists='replace')\n",
    "sql_df = pd.read_sql('sample_table', engine, index_col='Respondent')\n",
    "sql_df.head()\n",
    "sql_df = pd.read_sql('SELECT * FROM sample_table', engine, index_col='Respondent')\n",
    "\n",
    "# URL\n",
    "post_df = pd.read_json('https:etc')\n",
    "post_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Scratch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7b431e7fbd70f97146b7796044d8b3849592fbc5f677a8b91ae9f8b98d0697c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
