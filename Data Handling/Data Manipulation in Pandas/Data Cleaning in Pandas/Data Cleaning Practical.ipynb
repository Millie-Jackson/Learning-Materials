{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "flights_df = pd.read_csv(\"flights.txt\", sep=\"|\") # Make sure flights.txt is in the same directory\n",
    "first5 = flights_df.head(5) # Returns first 5 rows\n",
    "#print(flights_df) # Displays the database\n",
    "#print(flights_df.dtypes) # Displays the variable types\n",
    "\n",
    "duplicates = {'ORIGAIRPORTNAME': first5.duplicated('ORIGAIRPORTNAME').sum(),\n",
    "                'DESTAIRPORTNAME': first5.duplicated('DESTAIRPORTNAME').sum(),\n",
    "                'AIRLINECODE': first5.duplicated('AIRLINECODE').sum(),\n",
    "                'FLIGHTDATE': first5.duplicated('FLIGHTDATE').sum(),\n",
    "                'FLIGHTDATE': first5.duplicated('FLIGHTDATE').sum(),\n",
    "                'DEPTIME': first5.duplicated('DEPTIME').sum(),\n",
    "                'ARRTIME': first5.duplicated('ARRTIME').sum()}\n",
    "#print('DUPLICATES: ', duplicates)\n",
    "#print(first5[duplicates])\n",
    "#first5.duplicated(subset=['DESTAIRPORTNAME'])\n",
    "\n",
    "# Sort by column to manually review duplicates\n",
    "first5.sort_values(by='ORIGAIRPORTNAME')\n",
    "# Returns how many N/A in the column\n",
    "first5[\"CRSARRTIME\"].isna().sum()\n",
    "\n",
    "# Put all means columns in a dictionary\n",
    "summaries = {\"CRSARRTIME\": \"mean\", \"ARRTIME\": \"mean\", \"ARRDELAY\": \"mean\", \"CRSELAPSEDTIME\": \"mean\", \"ACTUALELAPSEDTIME\": \"mean\"}\n",
    "\n",
    "# Split into duplicates and organise by column name\n",
    "grouped_duplicates = flights_df[duplicates].groupby([\"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\"])\n",
    "# Return the minimum and reset index to default\n",
    "grouped_duplicates_min_transactionid = grouped_duplicates[\"TRANSACTIONID\"].min().reset_index()\n",
    "\n",
    "# Merge\n",
    "f_df_duplicates = pd.merge(\n",
    "    grouped_duplicates_min_transactionid, # Merge this\n",
    "    grouped_duplicates.agg(summaries).reset_index(), # With this\n",
    "    how=\"inner\" # by preserving the order of the left keys\n",
    ").sort_values(\"TRANSACTIONID\") # And sort by this column\n",
    "\n",
    "f_df_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTANCE\n",
    "\n",
    "# Get sum of distance column\n",
    "print(first5['DISTANCE'].sum(min_count=5))\n",
    "\n",
    "# Remove miles\n",
    "first5['DISTANCE'] = first5['DISTANCE'].str.strip('miles')\n",
    "print(first5['DISTANCE'].sum(min_count=5))\n",
    "\n",
    "# Convert column to float\n",
    "first5['DISTANCE'] = first5['DISTANCE'].astype('float64')\n",
    "print(first5.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUPLICATES\n",
    "\n",
    "# Put all duplicates in a dictionary\n",
    "duplicates = {'ORIGAIRPORTNAME': first5.duplicated('ORIGAIRPORTNAME').sum(),\n",
    "                'DESTAIRPORTNAME': first5.duplicated('DESTAIRPORTNAME').sum(),\n",
    "                'AIRLINECODE': first5.duplicated('AIRLINECODE').sum(),\n",
    "                'FLIGHTDATE': first5.duplicated('FLIGHTDATE').sum(),\n",
    "                'FLIGHTDATE': first5.duplicated('FLIGHTDATE').sum(),\n",
    "                'DEPTIME': first5.duplicated('DEPTIME').sum(),\n",
    "                'ARRTIME': first5.duplicated('ARRTIME').sum()}\n",
    "\n",
    "# Detects duplicates\n",
    "print('DUPLICATES: ', duplicates)\n",
    "# Returns the number of duplicates\n",
    "print(first5[duplicates])\n",
    "# Returns the actual duplicates\n",
    "first5.duplicated(subset=['DESTAIRPORTNAME'])\n",
    "\n",
    "# Sort by column to manually review duplicates\n",
    "first5.sort_values(by='ORIGAIRPORTNAME')\n",
    "# Returns how many N/A in the column\n",
    "first5[\"CRSARRTIME\"].isna().sum()\n",
    "\n",
    "# Put all means columns in a dictionary\n",
    "summaries = {\"CRSARRTIME\": \"mean\", \"ARRTIME\": \"mean\", \"ARRDELAY\": \"mean\", \"CRSELAPSEDTIME\": \"mean\", \"ACTUALELAPSEDTIME\": \"mean\"}\n",
    "\n",
    "# Split into duplicates and organise by column name\n",
    "grouped_duplicates = flights_df[duplicates].groupby([\"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\"])\n",
    "# Return the minimum and reset index to default\n",
    "grouped_duplicates_min_transactionid = grouped_duplicates[\"TRANSACTIONID\"].min().reset_index()\n",
    "\n",
    "# Merge\n",
    "f_df_duplicates = pd.merge(\n",
    "    grouped_duplicates_min_transactionid, # Merge this\n",
    "    grouped_duplicates.agg(summaries).reset_index(), # With this\n",
    "    how=\"inner\" # by preserving the order of the left keys\n",
    ").sort_values(\"TRANSACTIONID\") # And sort by this column\n",
    "\n",
    "f_df_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSACTIONID: Unique identifer\n",
    "\n",
    "FLIGHTDATE: Date of the flight. Looks like its encoded as a number instead of a date object\n",
    "\n",
    "TAILNUM: Looks like it contains @@ in some of its rows.\n",
    "\n",
    "ORIGAIRPORTNAME and DESTAIRPORTNAME: Looks like it has the city name and state concatenated and appended before the actual name of the airport\n",
    "\n",
    "CRSDEPTIME and DEPTIME: Look like they represent incorrectly formatted (military) times. Also it seems to be that CRSDEPTTIME + DEPDELAY = DEPTIME\n",
    "\n",
    "DEPDELAY: Departure delay in minutes?\n",
    "\n",
    "TAXIOUT: How long it took from departure to wheels off. Looks like DEPTIME + TAXIOUT = WHEELSOFF\n",
    "\n",
    "WHEELSOFF: The (military) time when wheels left the ground\n",
    "\n",
    "WHEELSON: Military time when wheels touched the ground on descent\n",
    "\n",
    "TAXIIN: Looks like the number of minutes since the wheels touched the ground to \"parking\"\n",
    "\n",
    "CRSARRTIME: The military encoded expected arrival time\n",
    "\n",
    "ARRTIME: Actual arrival time\n",
    "\n",
    "ARRDELAY: Difference between CRSARRTIME and ARRTIME\n",
    "\n",
    "CRSELAPSEDTIME: Planned journey time (minutes)\n",
    "\n",
    "ACTUALELAPSEDTIME: Actual journey time (minutes)\n",
    "\n",
    "CANCELLED: Whether the flight was cancelled or not. Looks like some values are False, others are F, and others 0. Possibly a similar variation for True\n",
    "\n",
    "DIVERTED: Whether the plane was diverted. Similar issues regarding True/False as above?\n",
    "\n",
    "DISTANCE: The (integer) distance the plane travelled, encoded as a string with \"miles\" concatenated to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([        'United Kingdom', 'Bosnia and Herzegovina',\\n                     'Thailand',          'United States',\\n                      'Ukraine',                 'Canada',\\n                      'Ukraine',                  'India',\\n                  'New Zealand',                  'India',\\n       ...\\n                            nan,                      nan,\\n                     'Pakistan',                  'Spain',\\n                'United States',                 'Canada',\\n                            nan,                      nan,\\n                            nan,                  'Spain'],\\n      dtype='object', name='Respondent', length=88883)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\Scratch\\Data Cleaning\\Data Cleaning Practical.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/Scratch/Data%20Cleaning/Data%20Cleaning%20Practical.ipynb#ch0000004?line=11'>12</a>\u001b[0m filt \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mCountry\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/Scratch/Data%20Cleaning/Data%20Cleaning%20Practical.ipynb#ch0000004?line=12'>13</a>\u001b[0m \u001b[39m#country_grp = df.groupby(['Country'])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/Scratch/Data%20Cleaning/Data%20Cleaning%20Practical.ipynb#ch0000004?line=13'>14</a>\u001b[0m df\u001b[39m.\u001b[39;49mloc[filt][\u001b[39m'\u001b[39m\u001b[39mLanguageWorkedWith\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39m'\u001b[39m\u001b[39mPython\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mvalue_counts(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1193\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1329\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([        'United Kingdom', 'Bosnia and Herzegovina',\\n                     'Thailand',          'United States',\\n                      'Ukraine',                 'Canada',\\n                      'Ukraine',                  'India',\\n                  'New Zealand',                  'India',\\n       ...\\n                            nan,                      nan,\\n                     'Pakistan',                  'Spain',\\n                'United States',                 'Canada',\\n                            nan,                      nan,\\n                            nan,                  'Spain'],\\n      dtype='object', name='Respondent', length=88883)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('survey_results_public.csv', index_col='Respondent')\n",
    "df_schema = pd.read_csv('survey_results_schema.csv', index_col='Column')\n",
    "\n",
    "#df.shape\n",
    "#df.info()\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)\n",
    "\n",
    "\n",
    "filt = df['Country']\n",
    "#country_grp = df.groupby(['Country'])\n",
    "df.loc[filt]['LanguageWorkedWith'].str.contains('Python').value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
